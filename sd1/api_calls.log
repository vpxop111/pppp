{"timestamp": "2025-04-28T14:35:16.786726", "provider": "openai", "model": "gpt-4", "prompt_length": 46846, "response_length": 0, "duration_seconds": 0.0, "status": "error", "error": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n", "metadata": {"temperature": 0.7, "max_tokens": 1000}}
{"timestamp": "2025-04-28T14:36:27.870776", "provider": "openai", "model": "gpt-4", "prompt_length": 46846, "response_length": 0, "duration_seconds": 3.755, "status": "error", "error": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4 in organization org-sTHzTXmRLC0HITFvvoz8eAuL on tokens per min (TPM): Limit 10000, Requested 11714. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "metadata": {"temperature": 0.7, "max_tokens": 1000}}
{"timestamp": "2025-04-28T14:37:54.532829", "provider": "openai", "model": "gpt-4.1-mini", "prompt_length": 46846, "response_length": 873, "duration_seconds": 8.595, "status": "success", "metadata": {"temperature": 0.7, "max_tokens": 16000}}
{"timestamp": "2025-04-28T14:41:15.149747", "provider": "openai", "model": "gpt-4.1-mini", "prompt_length": 46846, "response_length": 870, "duration_seconds": 4.297, "status": "success", "metadata": {"temperature": 0.7, "max_tokens": 16000}}
{"timestamp": "2025-04-28T14:43:56.023330", "provider": "openai", "model": "gpt-4.1-mini", "prompt_length": 46846, "response_length": 840, "duration_seconds": 4.323, "status": "success", "metadata": {"temperature": 0.7, "max_tokens": 16000}}
